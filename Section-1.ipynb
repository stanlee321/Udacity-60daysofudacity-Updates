{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "according to the lectures, we define the privacy as the action of removing somethign from the db without affecting the statistics of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parallel databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# the number of entries in our database\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a funcion to remove element x in db.\n",
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index], db[remove_index+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parallel_db(db, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now removing x + 1 elemetns of the db and creating a db with at least all\n",
    "# all the participants removed.\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    \n",
    "    parallel_dbs = []\n",
    "    \n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbs = get_parallel_dbs(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Final function thath condeces all the work.\n",
    "\n",
    "def create_db_and_parallel(num_entries):\n",
    "\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    return db, pdbs\n",
    "\n",
    "db, pdbs = create_db_and_parallel(30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_db_result = query(db)\n",
    "full_db_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 0\n",
    "\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query(pdb)\n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    \n",
    "    if (db_distance > sensitivity):\n",
    "        sensitivity = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity\n",
    "\n",
    "The maximun ammount that the query changes  when removing an individual from the datbase is called the **L1 sensitivity** or  **sensitivity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_and_parallel(num_entries):\n",
    "\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    return db, pdbs\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    \n",
    "    parallel_dbs = []\n",
    "    \n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P3 - Evaluating the privacy of a function\n",
    "\n",
    "def sensitivity(query, n_entries=1000):\n",
    "    db, pdbs = create_db_and_parallel(n_entries)\n",
    "    \n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    max_distance =0\n",
    "    \n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        \n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Project Calculate L1 for threshhold\n",
    "    \n",
    "def query(db, threshold = 5):\n",
    "    return (db.sum() > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(255, dtype=torch.uint8)\n",
      "tensor(255, dtype=torch.uint8)\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n",
      "0\n",
      "0\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sens_f = sensitivity(query,n_entries=10)\n",
    "    print(sens_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project: Perform a differential Atack\n",
    "\n",
    "db, _ = create_db_and_parallel(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb = get_parallel_db(db, remove_index=10)\n",
    "\n",
    "db[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff atack using sum query\n",
    "\n",
    "sum(db) - sum(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0046)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff atack using mean query\n",
    "\n",
    "(sum(db).float() / len(db)) - (sum(pdb).float()/ len(pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diff atack using threshold\n",
    "(sum(db).float() > 49) - (sum(pdb).float()  > 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5\n",
    "\n",
    "Local diff privacy and Global diff privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local diff pravacy??\n",
    "Each individual adds noice to their data before sending it to the statistical db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential privacy always requires a form of randommness or noise added to the query to protect from things like diff atacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plausible deniability\n",
    "\n",
    "# Project: Local Diff priv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_result = torch.mean(db.float())\n",
    "true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    \n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmented_database = db.float()*first_coin_flip + (1 - first_coin_flip)* second_coin_flip\n",
    "    db_result = torch.mean(augmented_database.float())*2 - 0.5\n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4926), tensor(0.5020))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(10000)\n",
    "query(db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more dataset , the query goes to the true value fot the corrupted db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 5.  Varying the Amount of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db, noise=0.2):\n",
    "    \n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmented_database = db.float()*first_coin_flip + (1 - first_coin_flip)* second_coin_flip\n",
    "    \n",
    "    sk_result = augmented_database.float().mean()\n",
    "    \n",
    "    private_result = ((sk_result/noise) - 0.5 )*noise/(1-noise)\n",
    "    \n",
    "    db_result = torch.mean(augmented_database.float())*2 - 0.5\n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With noise: 0.5399999618530273\n",
      "With out noise: 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(100)\n",
    "\n",
    "private_result, true_result = query(db,noise=0.1)\n",
    "\n",
    "print(f\"With noise: {private_result}\")\n",
    "print(f\"With out noise: {true_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With noise: 0.4983999729156494\n",
      "With out noise: 0.4950999915599823\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(10000)\n",
    "\n",
    "private_result, true_result = query(db,noise=0.9)\n",
    "\n",
    "print(f\"With noise: {private_result}\")\n",
    "print(f\"With out noise: {true_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White the point number increases (database size) , you can add more noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global diff privacy\n",
    "\n",
    "It is a wa to know how much information is leakyng a query\n",
    "\n",
    "$\\epsilon$ and $\\delta$ are measure the threshold for the leakage\n",
    "\n",
    "**When prefer local diff privacy**\n",
    "\n",
    "When the data is so sensitive, the people are going not to giving to you, prefers *local diff priv* because  the individual data owners want to protect their data before sending it to the thrsted curator.\n",
    "\n",
    "**Global diff priv** \n",
    "\n",
    "When there are most interest in saying \" I need the output of this query accurate while still having the same level of privacy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much noise we must add**\n",
    "\n",
    "Depends on:\n",
    "\n",
    "* Type of noise (Laplacian / Gaussian)\n",
    "* Sensitivity of query\n",
    "* Desired epsilon\n",
    "* Desired delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Demo Create a Differentially Private Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()\n",
    "\n",
    "def mean_query(db):\n",
    "    return toch.mean(db.float())\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_mechanism(db, query, sensitivity):\n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
    "    return query(db) + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41.6836], dtype=torch.float64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(db,sum_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43.0509], dtype=torch.float64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(db,sum_query, 1/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Intro Example Scenario Deep Learning in a Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_teachers = 10\n",
    "num_exampls = 10000\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (np.random.rand(num_teachers, num_exampls) * num_labels).astype(int).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = list()\n",
    "for an_image in preds:\n",
    "\n",
    "    label_counts = np.bincount(an_image, minlength=num_labels)\n",
    "\n",
    "    epsilon  = 0.1\n",
    "    beta = 1/epsilon\n",
    "\n",
    "    for i in range(len(label_counts)):\n",
    "        label_counts[i] += np.random.laplace(0,beta, 1)\n",
    "\n",
    "    new_label = np.argmax(label_counts)\n",
    "    \n",
    "    new_labels.append(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATE Analysis\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syft\n",
      "  Using cached https://files.pythonhosted.org/packages/36/e0/7466833685e21917a78b3e26503e675c9bc82bd81c0d9a6a90c30adf9938/syft-0.1.20a1-py3-none-any.whl\n",
      "Collecting scikit-learn>=0.21.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.7MB 58kB/s ta 0:00:014    50% |████████████████▎               | 3.4MB 23kB/s eta 0:02:19\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from syft) (0.3.0)\n",
      "Collecting websockets>=7.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/53/1dbfbe51e8ba9a2b9bc0b7201df77fe597f1e57b6b5d9bb094d3729aeecf/websockets-7.0-cp37-cp37m-manylinux1_x86_64.whl (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 35kB/s ta 0:00:018\n",
      "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from syft) (1.0.2)\n",
      "Collecting lz4>=2.1.6 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/20/de13b2899caef2323531b10bc71711180fab34d64ef25e40019c7f8d36c6/lz4-2.1.10-cp37-cp37m-manylinux1_x86_64.whl (387kB)\n",
      "\u001b[K    100% |████████████████████████████████| 389kB 325kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from syft) (1.1.0)\n",
      "Collecting tblib>=1.4.0 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/b5/ebb1af4d843047ccd7292b92f5e5f8643153e8b95d14508d9fe3b35f7004/tblib-1.4.0-py2.py3-none-any.whl\n",
      "Collecting flask-socketio>=3.3.2 (from syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.56.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 406kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
      "\u001b[K    100% |████████████████████████████████| 450kB 564kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tf-encrypted>=0.5.4 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 42kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: msgpack>=0.6.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from syft) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from syft) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.21.0->syft) (1.2.1)\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.21.0->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K    100% |████████████████████████████████| 286kB 533kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from torchvision>=0.3.0->syft) (5.4.1)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (0.14.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from Flask>=1.0.2->syft) (2.10)\n",
      "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 436kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from tf-encrypted>=0.5.4->syft) (5.1)\n",
      "Collecting tensorflow<2,>=1.12.0 (from tf-encrypted>=0.5.4->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.3MB 273kB/s ta 0:00:01 8% |██▉                             | 9.5MB 169kB/s eta 0:09:50    16% |█████▍                          | 18.3MB 385kB/s eta 0:03:56    19% |██████▎                         | 21.3MB 567kB/s eta 0:02:36    25% |████████                        | 27.4MB 183kB/s eta 0:07:27    32% |██████████▎                     | 35.2MB 179kB/s eta 0:06:54    33% |██████████▉                     | 36.9MB 349kB/s eta 0:03:28    62% |████████████████████            | 68.3MB 463kB/s eta 0:01:29    64% |████████████████████▋           | 70.4MB 603kB/s eta 0:01:05    67% |█████████████████████▌          | 73.2MB 194kB/s eta 0:03:06    82% |██████████████████████████▍     | 90.2MB 120kB/s eta 0:02:39    95% |██████████████████████████████▋ | 104.7MB 14kB/s eta 0:05:30    97% |███████████████████████████████ | 106.1MB 22kB/s eta 0:02:23\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
      "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 958kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.1)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.1)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/b1/b80dea9e0bbbdd07bf7ba69c6df1aeb3e88b90b85ca326c40be9e29bc37c/grpcio-1.22.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/86/9f6123c4c6f481862f286dbe13aa2e97bdedd7662f5fc3033c1a41f32f88/protobuf-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/stanlee321/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.9.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl (575kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: zstd, absl-py, gast, termcolor\n",
      "  Building wheel for zstd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stanlee321/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stanlee321/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stanlee321/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stanlee321/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built zstd absl-py gast termcolor\n",
      "Installing collected packages: joblib, scikit-learn, websockets, lz4, tblib, python-engineio, python-socketio, flask-socketio, websocket-client, zstd, keras-applications, absl-py, google-pasta, setuptools, markdown, grpcio, protobuf, tensorboard, gast, tensorflow-estimator, keras-preprocessing, termcolor, astor, tensorflow, tf-encrypted, syft\n",
      "  Found existing installation: scikit-learn 0.20.3\n",
      "    Uninstalling scikit-learn-0.20.3:\n",
      "      Successfully uninstalled scikit-learn-0.20.3\n",
      "  Found existing installation: tblib 1.3.2\n",
      "    Uninstalling tblib-1.3.2:\n",
      "      Successfully uninstalled tblib-1.3.2\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 flask-socketio-4.1.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.22.0 joblib-0.13.2 keras-applications-1.0.8 keras-preprocessing-1.1.0 lz4-2.1.10 markdown-3.1.1 protobuf-3.8.0 python-engineio-3.8.2.post1 python-socketio-4.2.0 scikit-learn-0.21.2 setuptools-41.0.1 syft-0.1.20a1 tblib-1.4.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install syft\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
