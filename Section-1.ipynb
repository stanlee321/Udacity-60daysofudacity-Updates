{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "according to the lectures, we define the privacy as the action of removing somethign from the db without affecting the statistics of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate parallel databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# the number of entries in our database\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a funcion to remove element x in db.\n",
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index], db[remove_index+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parallel_db(db, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now removing x + 1 elemetns of the db and creating a db with at least all\n",
    "# all the participants removed.\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    \n",
    "    parallel_dbs = []\n",
    "    \n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbs = get_parallel_dbs(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Final function thath condeces all the work.\n",
    "\n",
    "def create_db_and_parallel(num_entries):\n",
    "\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    return db, pdbs\n",
    "\n",
    "db, pdbs = create_db_and_parallel(30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_db_result = query(db)\n",
    "full_db_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 0\n",
    "\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query(pdb)\n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    \n",
    "    if (db_distance > sensitivity):\n",
    "        sensitivity = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity\n",
    "\n",
    "The maximun ammount that the query changes  when removing an individual from the datbase is called the **L1 sensitivity** or  **sensitivity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_and_parallel(num_entries):\n",
    "\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    return db, pdbs\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    \n",
    "    parallel_dbs = []\n",
    "    \n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P3 - Evaluating the privacy of a function\n",
    "\n",
    "def sensitivity(query, n_entries=1000):\n",
    "    db, pdbs = create_db_and_parallel(n_entries)\n",
    "    \n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    max_distance =0\n",
    "    \n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        \n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Project Calculate L1 for threshhold\n",
    "    \n",
    "def query(db, threshold = 5):\n",
    "    return (db.sum() > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(255, dtype=torch.uint8)\n",
      "tensor(255, dtype=torch.uint8)\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n",
      "0\n",
      "0\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n",
      "tensor(255, dtype=torch.uint8)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sens_f = sensitivity(query,n_entries=10)\n",
    "    print(sens_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project: Perform a differential Atack\n",
    "\n",
    "db, _ = create_db_and_parallel(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb = get_parallel_db(db, remove_index=10)\n",
    "\n",
    "db[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff atack using sum query\n",
    "\n",
    "sum(db) - sum(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0046)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diff atack using mean query\n",
    "\n",
    "(sum(db).float() / len(db)) - (sum(pdb).float()/ len(pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diff atack using threshold\n",
    "(sum(db).float() > 49) - (sum(pdb).float()  > 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5\n",
    "\n",
    "Local diff privacy and Global diff privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local diff pravacy??\n",
    "Each individual adds noice to their data before sending it to the statistical db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential privacy always requires a form of randommness or noise added to the query to protect from things like diff atacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plausible deniability\n",
    "\n",
    "# Project: Local Diff priv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_result = torch.mean(db.float())\n",
    "true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    \n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmented_database = db.float()*first_coin_flip + (1 - first_coin_flip)* second_coin_flip\n",
    "    db_result = torch.mean(augmented_database.float())*2 - 0.5\n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4926), tensor(0.5020))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(10000)\n",
    "query(db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more dataset , the query goes to the true value fot the corrupted db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 5.  Varying the Amount of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db, noise=0.2):\n",
    "    \n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmented_database = db.float()*first_coin_flip + (1 - first_coin_flip)* second_coin_flip\n",
    "    \n",
    "    sk_result = augmented_database.float().mean()\n",
    "    \n",
    "    private_result = ((sk_result/noise) - 0.5 )*noise/(1-noise)\n",
    "    \n",
    "    db_result = torch.mean(augmented_database.float())*2 - 0.5\n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With noise: 0.5399999618530273\n",
      "With out noise: 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(100)\n",
    "\n",
    "private_result, true_result = query(db,noise=0.1)\n",
    "\n",
    "print(f\"With noise: {private_result}\")\n",
    "print(f\"With out noise: {true_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With noise: 0.4983999729156494\n",
      "With out noise: 0.4950999915599823\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallel(10000)\n",
    "\n",
    "private_result, true_result = query(db,noise=0.9)\n",
    "\n",
    "print(f\"With noise: {private_result}\")\n",
    "print(f\"With out noise: {true_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White the point number increases (database size) , you can add more noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global diff privacy\n",
    "\n",
    "It is a wa to know how much information is leakyng a query\n",
    "\n",
    "$\\epsilon$ and $\\delta$ are measure the threshold for the leakage\n",
    "\n",
    "**When prefer local diff privacy**\n",
    "\n",
    "When the data is so sensitive, the people are going not to giving to you, prefers *local diff priv* because  the individual data owners want to protect their data before sending it to the thrsted curator.\n",
    "\n",
    "**Global diff priv** \n",
    "\n",
    "When there are most interest in saying \" I need the output of this query accurate while still having the same level of privacy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much noise we must add**\n",
    "\n",
    "Depends on:\n",
    "\n",
    "* Type of noise (Laplacian / Gaussian)\n",
    "* Sensitivity of query\n",
    "* Desired epsilon\n",
    "* Desired delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Demo Create a Differentially Private Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallel(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()\n",
    "\n",
    "\n",
    "def M(db, query, sensitivity):\n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
    "    return query(db) + noise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
